{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "n66biqdlkVDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yDqDmImD640"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 棋譜データの読み込み"
      ],
      "metadata": {
        "id": "8UaVYXSbEFuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"!mkdir drive/MyDrive/colab\n",
        "\"!mkdir drive/MyDrive/colab/ai_reversi"
      ],
      "metadata": {
        "id": "eAiVfhzJNdhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/colab/ai_reversi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrEhq6y3O77R",
        "outputId": "d841c1c9-d7df-4e92-e988-4099b21f28c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kihuFixed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with open(\"drive/MyDrive/colab/ai_reversi/kihuFixed.txt\") as f:\n",
        "#  lines = f.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "tMqrzZB0O2-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFT3a_2BjquD",
        "outputId": "ef99cf09-45d8-4938-9477-5f76728a8707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6066496"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの前処理"
      ],
      "metadata": {
        "id": "h-ENZU0gEJ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_next_flipped(board, row, col):\n",
        "  flipped = []\n",
        "  for dx in range(-1,2):\n",
        "    for dy in range(-1,2):\n",
        "      if dx == 0 and dy == 0:\n",
        "        continue\n",
        "      flipped_tmp = []\n",
        "      for k in range(1,8):\n",
        "        x = row + dx*k\n",
        "        y = col + dy*k\n",
        "        if not (0<=x<8 and 0<=y<8):\n",
        "          flipped_tmp = []\n",
        "          break\n",
        "        if board[x*8+y] == 0:\n",
        "          flipped_tmp = []\n",
        "          break\n",
        "        if board[x*8+y] == 1:\n",
        "          flipped += flipped_tmp\n",
        "          break\n",
        "        if board[x*8+y] == 2:\n",
        "          flipped_tmp.append((x,y))\n",
        "\n",
        "  if not flipped:\n",
        "    #print(np.array(board).reshape((8,8)))\n",
        "    #print(row,col)\n",
        "    #assert False\n",
        "\n",
        "    # パス\n",
        "    return -1\n",
        "\n",
        "  board[row*8+col] = 1\n",
        "  for x,y in flipped:\n",
        "    board[x*8+y] = 1\n",
        "\n",
        "  #print(board.reshape((8,8)))\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i*8+j] == 1:\n",
        "        board[i*8+j] = 2\n",
        "      elif board[i*8+j] == 2:\n",
        "        board[i*8+j] = 1\n",
        "\n",
        "  return board"
      ],
      "metadata": {
        "id": "WBINSaIfEM8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board = np.zeros((64,),int)\n",
        "board[3*8+3] = board[4*8+4] = 1\n",
        "board[3*8+4] = board[4*8+3] = 2\n",
        "row, col = 3,5"
      ],
      "metadata": {
        "id": "zwd1avk7Gyc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_next_flipped(board.copy(), row, col).reshape((8,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArUNe2N1HEnv",
        "outputId": "e0dcf27f-9912-4e87-819a-b4d00e8dac64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 1 1 0 0]\n",
            " [0 0 0 2 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 2, 2, 2, 0, 0],\n",
              "       [0, 0, 0, 1, 2, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_next_action(before,after,row,col):\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if before[i*8+j]==0 and after[i*8+j] != 0 and (i,j) != (row,col):\n",
        "        return (i,j)\n",
        "\n",
        "  #print(np.array(before).reshape((8,8)))\n",
        "  #print(np.array(after).reshape((8,8)))\n",
        "  #print(row,col)\n",
        "  #assert False\n",
        "\n",
        "  # パス\n",
        "  return -1,-1"
      ],
      "metadata": {
        "id": "T8w5Qt2cHmRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_next_action(board.copy(), )"
      ],
      "metadata": {
        "id": "oNf48KzOIFgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  board = draw(X[i,:,:,0],X[i,:,:,1])\n",
        "  print(board)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbZuIO27GTqV",
        "outputId": "2eabcb0f-33bd-4090-8f00-9df6dd47e880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False,  True, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess():\n",
        "  tmp1,tmp2 = [],[]\n",
        "  with open(\"drive/MyDrive/colab/ai_reversi/kihuFixed.txt\") as f:\n",
        "    while line:=f.readline():\n",
        "      if len(tmp1) % 1000000 == 0:\n",
        "        print(f\"processing {len(tmp1)}-th...\")\n",
        "      line = line.strip().split()\n",
        "      if not line:\n",
        "        continue\n",
        "      t = list(map(int,line[:64]))\n",
        "      col,row = map(int,line[-4:-2])\n",
        "      row -= 1\n",
        "      col -= 1\n",
        "\n",
        "      if len(tmp1):\n",
        "        before = tmp1[-1][:]\n",
        "        row0,col0 = tmp2[-1]\n",
        "        after = generate_next_flipped(before[:], row0, col0)\n",
        "\n",
        "        # パスではない\n",
        "        if after != -1:\n",
        "          row2,col2 = find_next_action(before, t, row0, col0)\n",
        "          tmp1.append(after)\n",
        "          tmp2.append([row2,col2])\n",
        "\n",
        "      tmp1.append(t)\n",
        "      tmp2.append([row,col])\n",
        "\n",
        "  n_sample = len(tmp1)\n",
        "\n",
        "  tmp1 = np.array(tmp1, dtype=np.int8).reshape(n_sample,8,8)\n",
        "  tmp2 = np.array(tmp2, dtype=np.int8)\n",
        "\n",
        "  #print(tmp1.shape, tmp2.shape)\n",
        "\n",
        "  X = np.stack([(tmp1==1),(tmp1==2)],axis=0).transpose(1,2,3,0).astype(bool)\n",
        "\n",
        "  #print(X.shape)\n",
        "\n",
        "  y = np.zeros(shape=(n_sample,8,8), dtype=bool)\n",
        "  y[np.arange(n_sample),tmp2[:,0],tmp2[:,1]] = 1\n",
        "\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "rZR0X4IUTAYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = preprocess()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mKNZaT2-rU-",
        "outputId": "593ac80d-10fc-4b44-b4fb-a58af6f37d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing 0-th...\n",
            "processing 1000000-th...\n",
            "processing 2000000-th...\n",
            "processing 3000000-th...\n",
            "processing 5000000-th...\n",
            "processing 6000000-th...\n",
            "processing 7000000-th...\n",
            "processing 9000000-th...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augument_data(data,axes=(0,1)):\n",
        "  data90 = np.rot90(data,k=1,axes=axes)\n",
        "  data180 = np.rot90(data,k=2,axes=axes)\n",
        "  data270 = np.rot90(data,k=3,axes=axes)\n",
        "  return np.vstack([data,data90,data180,data270])"
      ],
      "metadata": {
        "id": "w5X9Dh8TO9wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = augument_data(X, axes=(1,2))\n",
        "y2 = augument_data(y, axes=(1,2))"
      ],
      "metadata": {
        "id": "sbDShI3_PnNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw(x1,x2):\n",
        "  ret = np.zeros((8,8),int)\n",
        "  ret[x1] = 1\n",
        "  ret[x2] = 2\n",
        "  #print(ret)\n",
        "  return ret"
      ],
      "metadata": {
        "id": "y7lxuERUAGcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(draw(X[i,:,:,0],X[i,:,:,1]))\n",
        "  print(y[i].astype(int))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnFOiRQjAaCx",
        "outputId": "ff6cb3c8-a049-4b8a-8c8a-ece8677a4b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 0 2 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0]\n",
            " [0 0 1 1 2 0 0 0]\n",
            " [0 0 0 1 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 2 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 0 2 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 1 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 2 0 0]\n",
            " [0 0 2 1 2 0 0 0]\n",
            " [0 0 2 2 1 0 0 0]\n",
            " [0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 1 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 1 2 2 0 0 0]\n",
            " [0 0 1 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 2 0 0]\n",
            " [0 0 2 1 2 0 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 1 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 1 2 0 0]\n",
            " [0 0 2 2 2 0 0 0]\n",
            " [0 0 2 1 2 0 0 0]\n",
            " [0 0 2 1 2 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 1 2 2 1 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 1 2 1 0 0 0]\n",
            " [0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1,:,:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZg2TqY0_r5Z",
        "outputId": "6c93032d-611a-42f7-c685-419548eb2701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False,  True, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False,  True, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRHiMevR_x40",
        "outputId": "0b140f9d-d4ce-4116-d3a0-ea417f012265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False,  True, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False],\n",
              "       [False, False, False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9T8uxCW9oeh",
        "outputId": "dab3b4cd-c031-4fff-d63d-9f6a48f0024a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37807816, 8, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"drive/MyDrive/colab/ai_reversi/state.npy\", X2)\n",
        "np.save(\"drive/MyDrive/colab/ai_reversi/action.npy\", y2)"
      ],
      "metadata": {
        "id": "WOZQmt7PhQiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "IiI_K1vFuTRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "utuoILXDt6Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def block(out_channels, ksize, pad=1):\n",
        "    return tf.keras.Sequential([\n",
        "        layers.Conv2D(out_channels, ksize, padding='same' if pad == 1 else 'valid', activation='relu')\n",
        "    ])\n",
        "\n",
        "def sl_policy():\n",
        "    ksize = 3\n",
        "    inputs = layers.Input(shape=(8, 8, 2))\n",
        "    h = block(64, ksize)(inputs)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = block(128, ksize)(h)\n",
        "    h = layers.Conv2D(1, 1, use_bias=False)(h)\n",
        "    h = layers.Flatten()(h)  # 2次元の出力を1次元に平坦化\n",
        "    outputs = layers.Dense(64)(h)  # 出力層のユニット数を64に設定し、活性化関数は指定しない\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "W5PtUxBctSmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# TPUの設定\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "# Google Driveのマウント\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVMCnEluccA",
        "outputId": "6e450744-61e1-49d0-f9ef-33a8fa07a692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.91.97.178:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1エポックの中で細かくチェックポイントを作るためのコールバック\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "class CustomCheckpoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, filepath, steps_per_epoch, save_freq):\n",
        "        super(CustomCheckpoint, self).__init__()\n",
        "        self.filepath = filepath\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.save_freq = save_freq\n",
        "        self.batch_counter = 0\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.batch_counter = 0  # エポックの開始時にバッチカウンターをリセット\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_counter += 1\n",
        "        if self.batch_counter % self.save_freq == 0:\n",
        "            # チェックポイントのファイルパスを設定\n",
        "            filepath = self.filepath.format(epoch=self.epoch + 1, batch=batch + 1)\n",
        "            self.model.save_weights(filepath, overwrite=True)\n",
        "            print(f'\\nSaved checkpoint to: {filepath}')"
      ],
      "metadata": {
        "id": "IwD_oXIsTx3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('drive/MyDrive/colab/ai_reversi/state.npy')\n",
        "y = np.load('drive/MyDrive/colab/ai_reversi/action.npy')"
      ],
      "metadata": {
        "id": "JOWoPE80kHa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.isnan(y).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQaWrJ6fnqhB",
        "outputId": "ff6e2ea8-1b03-4cfa-ba5a-f14679d22db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y==np.inf).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT0HyGiKoE9c",
        "outputId": "691317a1-078f-462a-910a-f7d01d3796d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pickle"
      ],
      "metadata": {
        "id": "THfQFyl5Gvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# チェックポイントのコールバック\n",
        "#checkpoint_path = \"/content/drive/MyDrive/colab/ai_reversi/reversi_model/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "\n",
        "# 学習データの読み込み\n",
        "#X_train = np.load('drive/MyDrive/colab/ai_reversi/state.npy')\n",
        "#y_train = np.load('drive/MyDrive/colab/ai_reversi/action.npy')\n",
        "\n",
        "# モデルの作成とコンパイル\n",
        "\"\"\"\n",
        "with strategy.scope():\n",
        "    #model = sl_policy()\n",
        "    with open(\"/content/drive/MyDrive/colab/ai_reversi/reversi_model/cp-2024-03-0821:15:05.760753.pickle\", \"rb\") as f:\n",
        "      model = pickle.load(f)\n",
        "      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\"\"\"\n",
        "\n",
        "#model = tf.keras.models.load_model(\"drive/MyDrive/colab/ai_reversi/reversi_model/cp-2024-03-08 11:52:25.652748.ckpt.data-00000-of-00001.h5\")\n",
        "\n",
        "#batch_size = 64\n",
        "#n = len(X_train)\n",
        "\n",
        "# split dataset because large-size data cause serializing error at TPU\n",
        "n = 37807816\n",
        "n_batch = 16\n",
        "\n",
        "for j in range(3):\n",
        "    for i in range(n_batch):\n",
        "\n",
        "      if j == 0 and i == 0:\n",
        "        continue\n",
        "\n",
        "      if j  == 0 and i <= 11:\n",
        "        continue\n",
        "\n",
        "      print(f\"Training the {i+1}-th block, the {j+1}-th iteration of the data...\")\n",
        "\n",
        "      X_train2 = np.load('drive/MyDrive/colab/ai_reversi/state.npy')[n//n_batch*i:min(n//n_batch*(i+1),n)].astype(float)\n",
        "      y_train2 = np.load('drive/MyDrive/colab/ai_reversi/action.npy')[n//n_batch*i:min(n//n_batch*(i+1),n)]\n",
        "      #y_train2 = tf.keras.utils.to_categorical(y_train2, num_classes=64)\n",
        "      y_train2 = np.array([np.argmax(one_hot.flatten()) for one_hot in y_train2])\n",
        "\n",
        "      #del X_train,y_train\n",
        "\n",
        "      # コールバックのインスタンス化\n",
        "      #steps_per_epoch = len(X_train2) // batch_size\n",
        "      #save_freq = steps_per_epoch // 10  # 1エポック内で10回保存する\n",
        "\n",
        "      #checkpoint_path = \"/content/drive/MyDrive/colab/ai_reversi/reversi_model/cp-{i:04}-{epoch:04d}-{batch:04d}.ckpt\"\n",
        "      #cp_callback = CustomCheckpoint(filepath=checkpoint_path, steps_per_epoch=steps_per_epoch, save_freq=save_freq)\n",
        "\n",
        "      checkpoint_path = f\"/content/drive/MyDrive/colab/ai_reversi/reversi_model/cp-{i:04d}\"\n",
        "      checkpoint_path += \"-{epoch:04d}.ckpt\"\n",
        "      checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "      cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "          filepath=checkpoint_path,\n",
        "          verbose=1,\n",
        "          save_weights_only=True)\n",
        "\n",
        "      model_path = f\"/content/drive/MyDrive/colab/ai_reversi/reversi_model/cp-{str(datetime.now()).replace(' ','')}\"\n",
        "\n",
        "      # 学習\n",
        "      #model.fit(X_train2, y_train2, epochs=1, callbacks=[cp_callback])\n",
        "      model.fit(X_train2, y_train2, epochs=1)\n",
        "\n",
        "      checkpoint = tf.train.Checkpoint(model=model)\n",
        "      local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "      checkpoint.write(\n",
        "          model_path + \".ckpt\",\n",
        "          options=local_device_option)\n",
        "\n",
        "      with open(model_path + \".pickle\", \"wb\") as f:\n",
        "          pickle.dump(model, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L0l_miQd1rV",
        "outputId": "7b5979fc-1e97-49b3-a255-b51fea94f1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the 13-th block, the 1-th iteration of the data...\n",
            "73844/73844 [==============================] - 945s 13ms/step - loss: 1.4268 - accuracy: 0.5199\n",
            "Training the 14-th block, the 1-th iteration of the data...\n",
            "73844/73844 [==============================] - 933s 13ms/step - loss: 1.4072 - accuracy: 0.5231\n",
            "Training the 15-th block, the 1-th iteration of the data...\n",
            "73844/73844 [==============================] - 881s 12ms/step - loss: 1.3070 - accuracy: 0.5516\n",
            "Training the 16-th block, the 1-th iteration of the data...\n",
            "73844/73844 [==============================] - 913s 12ms/step - loss: 1.3389 - accuracy: 0.5432\n",
            "Training the 1-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 930s 13ms/step - loss: 1.4194 - accuracy: 0.5220\n",
            "Training the 2-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 906s 12ms/step - loss: 1.4006 - accuracy: 0.5253\n",
            "Training the 3-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 886s 12ms/step - loss: 1.3003 - accuracy: 0.5533\n",
            "Training the 4-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 884s 12ms/step - loss: 1.3331 - accuracy: 0.5444\n",
            "Training the 5-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 873s 12ms/step - loss: 1.4094 - accuracy: 0.5248\n",
            "Training the 6-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 837s 11ms/step - loss: 1.3914 - accuracy: 0.5282\n",
            "Training the 7-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 864s 12ms/step - loss: 1.2898 - accuracy: 0.5564\n",
            "Training the 8-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 938s 13ms/step - loss: 1.3227 - accuracy: 0.5475\n",
            "Training the 9-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 919s 12ms/step - loss: 1.4026 - accuracy: 0.5268\n",
            "Training the 10-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 885s 12ms/step - loss: 1.3862 - accuracy: 0.5297\n",
            "Training the 11-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 870s 12ms/step - loss: 1.2858 - accuracy: 0.5576\n",
            "Training the 12-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 865s 12ms/step - loss: 1.3286 - accuracy: 0.5456\n",
            "Training the 13-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 847s 11ms/step - loss: 1.3970 - accuracy: 0.5284\n",
            "Training the 14-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 836s 11ms/step - loss: 1.3803 - accuracy: 0.5308\n",
            "Training the 15-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 832s 11ms/step - loss: 1.2792 - accuracy: 0.5594\n",
            "Training the 16-th block, the 2-th iteration of the data...\n",
            "73844/73844 [==============================] - 822s 11ms/step - loss: 1.3137 - accuracy: 0.5504\n",
            "Training the 1-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 832s 11ms/step - loss: 1.3892 - accuracy: 0.5309\n",
            "Training the 2-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 817s 11ms/step - loss: 1.3754 - accuracy: 0.5328\n",
            "Training the 3-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 813s 11ms/step - loss: 1.2728 - accuracy: 0.5615\n",
            "Training the 4-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 810s 11ms/step - loss: 1.3089 - accuracy: 0.5516\n",
            "Training the 5-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 808s 11ms/step - loss: 1.3843 - accuracy: 0.5323\n",
            "Training the 6-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 808s 11ms/step - loss: 1.3707 - accuracy: 0.5343\n",
            "Training the 7-th block, the 3-th iteration of the data...\n",
            "73844/73844 [==============================] - 810s 11ms/step - loss: 1.2678 - accuracy: 0.5627\n",
            "Training the 8-th block, the 3-th iteration of the data...\n",
            "51442/73844 [===================>..........] - ETA: 4:03 - loss: 1.3104 - accuracy: 0.5512"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the 2-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 918s 12ms/step - loss: 1.6377 - accuracy: 0.4607\n",
        "Training the 3-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 933s 13ms/step - loss: 1.5102 - accuracy: 0.4959\n",
        "Training the 4-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 918s 12ms/step - loss: 1.5202 - accuracy: 0.4932\n",
        "Training the 5-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 919s 12ms/step - loss: 1.6181 - accuracy: 0.4668\n",
        "Training the 6-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 941s 13ms/step - loss: 1.5588 - accuracy: 0.4814\n",
        "Training the 7-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 922s 12ms/step - loss: 1.4457 - accuracy: 0.5129\n",
        "Training the 8-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 928s 13ms/step - loss: 1.4588 - accuracy: 0.5095\n",
        "Training the 9-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 1125s 15ms/step - loss: 1.5499 - accuracy: 0.4849\n",
        "Training the 10-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 946s 13ms/step - loss: 1.5054 - accuracy: 0.4955\n",
        "Training the 11-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 940s 13ms/step - loss: 1.3985 - accuracy: 0.5253\n",
        "Training the 12-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 972s 13ms/step - loss: 1.4192 - accuracy: 0.5202\n",
        "Training the 13-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 925s 13ms/step - loss: 1.5140 - accuracy: 0.4946\n",
        "Training the 14-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 927s 13ms/step - loss: 1.4755 - accuracy: 0.5036\n",
        "Training the 15-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 968s 13ms/step - loss: 1.3727 - accuracy: 0.5325\n",
        "Training the 16-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 991s 13ms/step - loss: 1.3949 - accuracy: 0.5267Training the 2-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 918s 12ms/step - loss: 1.6377 - accuracy: 0.4607\n",
        "Training the 3-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 933s 13ms/step - loss: 1.5102 - accuracy: 0.4959\n",
        "Training the 4-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 918s 12ms/step - loss: 1.5202 - accuracy: 0.4932\n",
        "Training the 5-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 919s 12ms/step - loss: 1.6181 - accuracy: 0.4668\n",
        "Training the 6-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 941s 13ms/step - loss: 1.5588 - accuracy: 0.4814\n",
        "Training the 7-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 922s 12ms/step - loss: 1.4457 - accuracy: 0.5129\n",
        "Training the 8-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 928s 13ms/step - loss: 1.4588 - accuracy: 0.5095\n",
        "Training the 9-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 1125s 15ms/step - loss: 1.5499 - accuracy: 0.4849\n",
        "Training the 10-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 946s 13ms/step - loss: 1.5054 - accuracy: 0.4955\n",
        "Training the 11-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 940s 13ms/step - loss: 1.3985 - accuracy: 0.5253\n",
        "Training the 12-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 972s 13ms/step - loss: 1.4192 - accuracy: 0.5202\n",
        "Training the 13-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 925s 13ms/step - loss: 1.5140 - accuracy: 0.4946\n",
        "Training the 14-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 927s 13ms/step - loss: 1.4755 - accuracy: 0.5036\n",
        "Training the 15-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 968s 13ms/step - loss: 1.3727 - accuracy: 0.5325\n",
        "Training the 16-th block of the data...\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "73844/73844 [==============================] - 991s 13ms/step - loss: 1.3949 - accuracy: 0.5267"
      ],
      "metadata": {
        "id": "dIzVf7X49QFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the 1-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 1046s 14ms/step - loss: 1.4816 - accuracy: 0.5038"
      ],
      "metadata": {
        "id": "cAIcOZRmG7e6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the 2-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 972s 13ms/step - loss: 1.4500 - accuracy: 0.5109\n",
        "Training the 3-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 990s 13ms/step - loss: 1.3484 - accuracy: 0.5389\n",
        "Training the 4-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 999s 14ms/step - loss: 1.3741 - accuracy: 0.5321\n",
        "Training the 5-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 990s 13ms/step - loss: 1.4609 - accuracy: 0.5098\n",
        "Training the 6-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 998s 14ms/step - loss: 1.4333 - accuracy: 0.5155\n",
        "Training the 7-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 1019s 14ms/step - loss: 1.3323 - accuracy: 0.5439\n",
        "Training the 8-th block, the 1-th iteration of the data...\n",
        "55346/73844 [=====================>........] - ETA: 4:14 - loss: 1.3646 - accuracy: 0.5349"
      ],
      "metadata": {
        "id": "EhJelqe6rntW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\t\tTraining the 8-th block, the 1-th iteration of the data...\n",
        "\t\t73844/73844 [==============================] - 884s 12ms/step - loss: 1.3595 - accuracy: 0.5363\n",
        "\t\tTraining the 9-th block, the 1-th iteration of the data...\n",
        "\t\t73844/73844 [==============================] - 878s 12ms/step - loss: 1.4436 - accuracy: 0.5147\n",
        "\t\tTraining the 10-th block, the 1-th iteration of the data...\n",
        "\t\t73844/73844 [==============================] - 876s 12ms/step - loss: 1.4188 - accuracy: 0.5197\n",
        "\t\tTraining the 11-th block, the 1-th iteration of the data...\n",
        "\t\t73844/73844 [==============================] - 887s 12ms/step - loss: 1.3179 - accuracy: 0.5481\n",
        "\t\tTraining the 12-th block, the 1-th iteration of the data..."
      ],
      "metadata": {
        "id": "ucKVYnkMJ5Zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the 13-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 945s 13ms/step - loss: 1.4268 - accuracy: 0.5199\n",
        "Training the 14-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 933s 13ms/step - loss: 1.4072 - accuracy: 0.5231\n",
        "Training the 15-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 881s 12ms/step - loss: 1.3070 - accuracy: 0.5516\n",
        "Training the 16-th block, the 1-th iteration of the data...\n",
        "73844/73844 [==============================] - 913s 12ms/step - loss: 1.3389 - accuracy: 0.5432\n",
        "Training the 1-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 930s 13ms/step - loss: 1.4194 - accuracy: 0.5220\n",
        "Training the 2-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 906s 12ms/step - loss: 1.4006 - accuracy: 0.5253\n",
        "Training the 3-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 886s 12ms/step - loss: 1.3003 - accuracy: 0.5533\n",
        "Training the 4-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 884s 12ms/step - loss: 1.3331 - accuracy: 0.5444\n",
        "Training the 5-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 873s 12ms/step - loss: 1.4094 - accuracy: 0.5248\n",
        "Training the 6-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 837s 11ms/step - loss: 1.3914 - accuracy: 0.5282\n",
        "Training the 7-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 864s 12ms/step - loss: 1.2898 - accuracy: 0.5564\n",
        "Training the 8-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 938s 13ms/step - loss: 1.3227 - accuracy: 0.5475\n",
        "Training the 9-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 919s 12ms/step - loss: 1.4026 - accuracy: 0.5268\n",
        "Training the 10-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 885s 12ms/step - loss: 1.3862 - accuracy: 0.5297\n",
        "Training the 11-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 870s 12ms/step - loss: 1.2858 - accuracy: 0.5576\n",
        "Training the 12-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 865s 12ms/step - loss: 1.3286 - accuracy: 0.5456\n",
        "Training the 13-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 847s 11ms/step - loss: 1.3970 - accuracy: 0.5284\n",
        "Training the 14-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 836s 11ms/step - loss: 1.3803 - accuracy: 0.5308\n",
        "Training the 15-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 832s 11ms/step - loss: 1.2792 - accuracy: 0.5594\n",
        "Training the 16-th block, the 2-th iteration of the data...\n",
        "73844/73844 [==============================] - 822s 11ms/step - loss: 1.3137 - accuracy: 0.5504\n",
        "Training the 1-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 832s 11ms/step - loss: 1.3892 - accuracy: 0.5309\n",
        "Training the 2-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 817s 11ms/step - loss: 1.3754 - accuracy: 0.5328\n",
        "Training the 3-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 813s 11ms/step - loss: 1.2728 - accuracy: 0.5615\n",
        "Training the 4-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 810s 11ms/step - loss: 1.3089 - accuracy: 0.5516\n",
        "Training the 5-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 808s 11ms/step - loss: 1.3843 - accuracy: 0.5323\n",
        "Training the 6-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 808s 11ms/step - loss: 1.3707 - accuracy: 0.5343\n",
        "Training the 7-th block, the 3-th iteration of the data...\n",
        "73844/73844 [==============================] - 810s 11ms/step - loss: 1.2678 - accuracy: 0.5627\n",
        "Training the 8-th block, the 3-th iteration of the data...\n",
        "51442/73844 [===================>..........] - ETA: 4:03 - loss: 1.3104 - accuracy: 0.5512"
      ],
      "metadata": {
        "id": "YLHJJ31EBnep"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jHoHQc8kHudV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}